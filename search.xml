<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql总结（一）]]></title>
    <url>%2F2017%2F12%2F30%2Fmysql%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[mysql是Java工程师面试时最经常被问到的技术点，因为mysql技术点太多了，很容易考察出被面试人的技术广度和深度。现总结一下mysql的基础知识点，但只是一份入门级的总结，不会太深入，期望能尽量覆盖到mysql常用知识点。另外，因为是总结，有些知识点会直接从其他地方拷贝，包括图片（图侵删）等，不喜勿喷。 本篇总结主要按照以下结构分别阐述： mysql数据引擎，重点介绍innodb数据引擎 innodb与myisam引擎的区别 innodb的逻辑存储结构 innodb 特性 innodb索引 innodb索引原理，B/B+树简单介绍 索引的使用和优化经验。 SQL优化经验和大数据量下的数据存储优化 mysql事务和锁 mysql性能调优，主要是常用配置的优化 mysql集群和高可用 mysql主从同步原理 mysql集群搭建方案 mysql高可用方案 mysql数据引擎，innodb引擎mysql数据引擎主要有MyIsam、Innodb、Merge、Blackhole、Berkeley、CSV、Cluster/NDB等引擎。用的最多的就是MyIsam和Innodb两种引擎。 MyIsam引擎和Innodb的区别 Innodb提供了对数据库ACID事务的支持，MyIsam不支持事务； Innodb支持行级锁，MyIsam只支持表级锁； Innodb支持外键约束，MyIsam不支持； Innodb索引是聚集索引，索引文件即是数据文件，后面说到索引的时候会详细说明，MyIsam是非聚集索引，索引文件不存实际数据。 MyIsam支持全文索引，并且存储了表的行数，Innodb不支持全文索引，没有存储表的行数，因此 SELECT COUNT(*) FROM TABLE 会引起全表扫描。 Innodb的逻辑存储结构主要介绍InnoDB存储引擎表的逻辑存储以及实现。 索引组织表先看一个官方文档说明： clustered indexThe InnoDB term for a primary key index. InnoDB table storage is organized based on the values of the primary key columns,to speed up queries and sorts involving the primary key columns. For best performance, choose the primary key columns carefullybased on the most performance-critical queries. Because modifying the columns of the clustered index is an expensive operation,choose primary columns that are rarely or never updated.In the Oracle Database product, this type of table is known as an index-organized table. 翻译一下就是，Innodb数据存储是基于主键值的，通过主键可以提高查询和排序速度。因此，为了提高性能，应该谨慎的选择主键字段。修改聚集索引的字段是一个昂贵的操作，主键不应该被修改。在Oracle的数据库产品中，这种表叫做索引组织表。 按照主键的顺序存储，即索引组织表，innodb中的每个表都有一个主键，即使用户没有显式的设置一个主键，mysql也会为这张表生成一个主键，主键的生成规则： 用户显式的创建主键字段； 如果显式创建主键字段，判断表中是否有非空的唯一索引，若有，则为主键； 如果1，2都不满足，则Innodb自动生成一个6字节大小的隐式主键。 索引组织表Innodb中所有的数据都被逻辑地存放在一个空间中，称之为表空间(tablespace)。表空间又由段(segment)、区(extent)、页(page)、行（row）组成。InnoDB存储引擎的逻辑存储结构如下图表空间 Tablespace表空间是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。表空间又分为独立表空间和共享表空间。通过参数innodb_file_per_table参数来决定使用何种类型的表空间。但是需要注意的是独立表空间内只存放数据、索引和插入缓冲页，其他的数据，如回滚(undo)信息、插入缓冲索引页、系统事务信息、二次写缓冲(double write buffer)等还是放在共享表空间中。段 Segment表空间由各个段组成。常见的段有数据段、索引段、回滚段等。InnoDB存储引擎是索引组织表，因此数据及索引，索引即数据。数据段即为B+树的叶子点(leaf node segment)，索引段为B+数据的非叶子节点(non-leaf node segment)。区 Extent区是由连续页组成的空间。InnoDB存储引擎页的大小为16KB，一个区有64个连续的页组成，所以每个区的大小都是1MB。InnoDB 1.0.x版本开始引入压缩页，即每个页的大小可以在建表时通过参数key_block_size设置为2K、4K、8K，因此每个区对于页的数量就为512、256、126。InnoDB 1.2.X版本新增参数innodb_page_size将默认页的大小设置为4K、8K，但是页中的数据不是压缩，这是其中的数量同样为256、128。一句话，不论页的大小怎么变化，区的大小不变1M。但是有这样一个问题：在开启独立表空间之后，创建的表默认大小是96K，区中是64个连续的页，创建的表空间应该是1M才对呀？这是因为在每个段的开始时，先用32个页大小的碎片页(fragment page)来保存数据，在使用完这些页之后才是64个连续的页的申请。这样做是对于一些小表或者undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。页 Page页是InnoDB磁盘管理的最小单位。默认大小为16K，可以通过innodb_page_size将页的大小设置为4K、8K、16K，则所有表中页的大小都为设置值，不可以对其再次修改。除非通过mysqldump导入和导出操作来产生新的库。常见的页的类型有:数据页(B-tree Node)、undo页(unod Log Page)、系统页(System Page)、事务数据页(Transaction system Page)、插入缓冲空闲列表页(Insert Buffer Free List)、未压缩的二进制大对象页(Uncompressed BLOB Page)、压缩的二进制对象页(compressed BLOB Page)。行 RowInnoDB存储引擎是面向行的(row-oriented)，也就是说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多运行存放16K/2-200行的记录，即7992行记录。 Innodb关键特性innodb存储引擎的关键特性包括：插入缓冲，两次写，自适应哈希索引插入缓冲主键是行唯一的标识符，在应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的，因此，插入聚集索引一般是顺序的，不需要磁盘的随机读取。Innodb设计了插入缓冲，对于非聚集索引的插入或更新插入，不是每一次直接插入索引页，而是先判断插入的非聚集索引页是否在缓冲池。如果在，则直接插入；如果不在，则先放入一个插入缓冲区中，然后再以一定的频率执行插入缓冲和非聚集索引页子节点的合并操作，这时通常能将多个插入合并到一个操作中，这就大大提高了对非聚集索引执行插入和修改操作的性能。插入缓冲的两个条件：索引是辅助索引；索引不是唯一的。 两次写当数据库死机时，可能发生数据库正在写一个页面，而这个页只写来了一部分，我们称之为部分写失效。有人想如果发生写失效，可以重做日志（redo log）进行恢复。这是一个办法的但必须清楚，重做日志分析记录的是对页的物理操作，如果这个页本身已经损坏（脏页），再对其重做也没意义。当写入部分失效时，先通过页的副本来还原该页，再进行重做，这就是double write。double write由两部分组成：一部分是内存池中的double write buffer，另一部分是物理磁盘上的共享表空间中的连续的128个页，即两个区。当缓冲页的脏页刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先拷贝到内存中的double write buffer .之后通过double write buffer再分两次，每次写入1MB到共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲带来的问题。 自适应哈希引擎哈希是一种非常快的查找方法，一般情况下查找时间的复杂度为O（1），常用于连接操作，Innodb会监控对表上索引的查找，如果观察到建立哈希索引可以带来速度的提升，则自动建立哈希索引，所以称之为自适应的。自适应哈希索引通过缓冲池中的B++树构造而来，因此建立的速度会很快。而且不需要将整个表都建立哈希索引，Innodb会自动根据访问的频率和模式来为某些页建立哈希索引。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年总结]]></title>
    <url>%2F2017%2F12%2F30%2F2017%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[生活儿子的出生当是2017年的头等大事，我自己非常喜欢小孩，对于儿子的出生自然喜不自胜。儿子出生那天，我说希望儿子以后健康、独立、快乐，这也是我对儿子未来的祝福。健康要放在首位，身体好才能担得起未来你身上的责任。独立，是希望你以后要学会思考，要有自己的个性，不盲目从众，以独立之思考、决定从容应对以后的工作和生活。快乐，是对你人生的祝福，希望你能感受到这个世界的美好，有一个美好的人生，也希望你以后莫要陷入人生的陷阱，人生可以很难，也可以很简单，希望你无时无刻都快乐。 老婆生孩子糟了不少罪，很是心疼，我本不是一个浪漫的人，不会制造惊喜，日子过得波澜不惊，幸而老婆也不是很在意。新的一年，一定要多多疼爱老婆，逢年过节，一束鲜花，以表心意。 父母家人都十分健康，幸甚，又添一侄子和外甥，家族日益庞大，父母老了，还要帮忙照看孩子，也是辛苦，然总也是老来之乐。 老婆的爷爷今年去世，让我想起了我爷爷去世，爷爷去世没来的及回去见最后一面，是我心头一大憾事，世事难料，对老人需要倍加珍惜。 2018年要保持身体健康，17年阑尾炎发作以及后面的手术，糟了不少罪。跑步要坚持下去，另外需要给家人买一份合适的保险。 其他没什么值得书写，如房子至今仍未装修，买车等等，一笔带过。 工作工作上，未来虽然仍不是很通透，但今年对我来说是非常重要的一年，想明白了一些事，也到了该想清楚以后的规划的时候了，希望2018年是爆发的一年。 2017年，一整年都还是在这家创业公司，最近刚刚办理了离职，从2016年4月份加入，1年8个月的时间，不长也不短。这段时间主要做了这么几件事： 从头开始搭建服务端架构，以dubbo为基础框架，结合自研的一些组件，完成了这套服务器架构，现在看，有很多不足，但足够公司用一两年，有这么长时间，架构升级就水到渠成了。 从16年12月份到17年4月份的架构重构项目，这是我带的最大的团队和项目，包括公司产品、Android、iOS和服务器、测试团队的大部分人员，作为项目负责人，带领小伙伴完成了产品梳理、架构设计、研发一直到上线，这个项目给公司以后的发展打下了基础，可以肯定的是，至少几年内，公司业务都还是要以这个架构为基础。 17年下半年，逐步的聚焦服务端团队，进行服务端架构升级和优化，包括服务性能优化、推动服务化、自动化等。 我很感激这段经历，对我自己是一个很好的成长。16年加入的时候，服务器端只有我自己一个人，产品也从头开始梳理，一步步看着服务器端架构搭建完善起来，一步步看着产品成形上线，投入的感情岂止一点两点，然而非常可惜，到最后还是毅然离开了。 回顾这接近两年的创业经历，诸多收获，也有诸多的困惑。当产品一次次推倒重来，当老板一次又一次任性的去设计产品，当僵硬的管理体制一次次限制了开放创新，我只感到力不从心，也害怕这样的工作对我以后会产生怎样的影响，First you hate ‘em, then you get used to ‘em. Enough time passes, gets so you depend on them. That’s institutionalized. –这些墙很有趣。刚入狱的时候，你痛恨周围的高墙；慢慢地，你习惯了生活在其中；最终你会发现自己不得不依靠它而生存。这就叫体制化。《肖申克的救赎》这句台词代表了我当时离职前的心情，也是我离职的最大原因。 然而回过头来看一看，创业哪有那么容易，也许就需要这么多一次次尝试，一次次挖坑埋坑，才能争取一次成功的机会，所以要么做好接受这一切的准备，要么不要去这种创业公司。有同事说，公司正要看到希望，如果真的成功了，你会不会后悔？我想说，怎么叫后悔呢？这个公司成功了就会后悔，没成功就不会后悔么？既然做出了选择，就没有后悔这一说了，所有的事都是你这次选择需要承担的，没有后悔，没有反悔。 那这一年到底想清楚了什么？我以前说过，我的梦想是创业，这一年让我看清了，想创业，实在是还差十万八千里，最重要的是思维，其次基本功还差太多，这个基本功包括很多，技术、管理、人际等等。因此2018年，希望能尽可能的去弥补。简单来说，2018年希望做好这几件事： 技术上要不断提高，开阔技术广度； 管理上不断学习，可能会去学一下管理方面的书籍或者课程，考一个管理方面的证书； 不断认识牛人，怎么认识？一个是公司内的大神，多接触一些，另一个是要多去参加技术论坛讲座，如果自己也能上去讲一下，最好不过了。 维护好自己的技术博客，维护一个技术公众号 2018年对我自己是非常重要的一年，我自己又有诸多懒散的毛病，因此flag立下了，仍然需要下些精力去执行，否则，待明年写2018年总结时又难免一阵苦恼懊悔，非善事也。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>2017</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbox源码分析]]></title>
    <url>%2F2017%2F06%2F20%2FDubbox%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[微服务架构微服务架构相比传统的单体架构，服务之前的依赖关系更加明确，服务职责单一，服务可以自治，在良好的服务治理体系下，可以极大提高系统的容错率以及系统的弹性。 但是相对的，微服务架构由于架构复杂，也会增加很多部署和运维成本，故障排查较困难，链路调用风险增大，团队协作成本也会上升。 如果纯粹是一名技术人员，肯定首选微服务架构，但是，从架构角度考虑，架构不单单是技术的选型，技术团队的方方面面都是需要衡量的，如团队成员的技术水平，开发流程（瀑布或敏捷），项目的大小、团队成员合理的协作方式、开发效率提升等等。其实，个人认为这些才是最难得。 在项目初期，尤其是对于创业公司来说，产品开发初期侧重点势必在于产品需求的实现，但是是基础架构的搭建不是一朝一夕就能完善的，这点要做好准备，基础平台的建设开始的越早越好，当然，前提是，老板支持。 DubboxDubbox(https://github.com/dangdangdotcom/dubbox)是当当网在阿里开源的Dubbo(http://dubbo.io/)基础上扩展而来。Dubbo阿里已经不维护了，Dubbox目前当当网基本也不再维护了，但是国内的Dubbo和Dubbox的用户还是非常多的，虽然社区活跃程度较低，但是基本问题都会找到解决方案的。建议有兴趣的同学研究一下Spring Cloud，再做决定。 严格来说，Dubbo或者Dubbox不是微服务架构的全套解决方案，个人认为Dubbox只是提供了服务发现、服务治理、服务降级的RPC框架。其他的组件需要自己开发或者引入第三方开源框架，如配置管理，DB Proxy，日志以及链路调用分析，熔断机制等等。有兴趣的同学，可以看下本人开源的Linkz(https://github.com/chuanqicc0430/Linkz)，提供了几个组件，可以结合Dubbox使用。 Dubbo主要提供服务注册发现、负载均衡、服务编排、服务降级、底层通信（可选Netty或Mina）、序列化等功能，架构图如下： 接下来，我会将阅读Dubbox的源码写下来，有兴趣的同学可以一块学习。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Netty实现的httpserver实现（二）]]></title>
    <url>%2F2016%2F02%2F19%2FNetty-Based-HttpServer-2%2F</url>
    <content type="text"><![CDATA[代码结构代码结构如下图所示： 其中： app: HttpApplication是业务层的基类，继承此类以实现具体业务；HttpApplication可携带上下文ApplicationContext，ApplicationContext提供编解码方法。 core: 核心层，配置、日志、过滤器、拦截器等都在这一层实现。 appHttpApplication12345678910111213public abstract class HttpApplication&lt;C extends ApplicationContext&gt; &#123; protected HttpApplication() &#123; &#125; public abstract void load() throws Exception; public abstract void unload() throws Exception; public abstract void process(ApplicationTx&lt;C&gt; tx) throws Exception;&#125; load(): 初始化资源；unload(): 释放资源；process(ApplicationTx tx): 执行业务，tx携带用户上下文和本次请求的httprequest和httpresponse； HttpPrefix12345678910@Retention(RetentionPolicy.RUNTIME)@Target(&#123; ElementType.TYPE &#125;)public @interface HttpPrefix &#123; String path(); String protocal(); HttpMethod[] method() default HttpMethod.GET;&#125; HttpPrefix注解标注了HttpApplication的请求路径，协议和方法（Post or Get）。 ApplicationContext123456789101112131415161718192021public abstract class ApplicationContext &#123; /** * * 从数据中解码 * * @param datas * @throws IOException */ public abstract void decode(byte[] datas) throws Exception; /** * * 按需编码 * * @param demand * @return */ public abstract byte[] encode(int demands) throws IOException;&#125; 用户上下文context基类，可自定义业务需要的contenxt类型。 ApplicationTx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ApplicationTx&lt;C extends ApplicationContext&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ApplicationTx.class); private C context = null; private byte[] contextData; private HttpServletRequest request; private HttpServletResponse response; public ApplicationTx(HttpServletRequest request, HttpServletResponse response) &#123; this.request = request; this.response = response; contextData = base64decode(request.getHeader("ContextData")); &#125; public C context() &#123; return context; &#125; public void setContext(C context) &#123; this.context = context; &#125; /** * &#123;在这里补充功能说明&#125; * * @param header * @return */ private byte[] base64decode(String header) &#123; return Base64.decode(header); // 暂不用decodeFast &#125; public HttpServletRequest getRequest() &#123; return request; &#125; public HttpServletResponse getResponse() &#123; return response; &#125; /** * &#123;在这里补充功能说明&#125; * * @return */ protected byte[] extractContextData() &#123; return contextData; &#125; public void processSucceed(String responseStr,String contentType) &#123; response.setStatus(200); response.setHeader("Content-Type", contentType); response.setHeader("Content-Length", String.valueOf(responseStr.length())); response.setHeader("Content-Language", "en"); try &#123; response.getWriter().write(responseStr); &#125; catch (IOException e) &#123; LOGGER.error("Send success response error!", e); &#125; &#125; public void processFailed(CUException error) &#123; response.setStatus(error.getReturnCode()); response.setHeader("Content-Type", "text/plain"); response.setHeader("Content-Length", String.valueOf(error.getMessage().length())); response.setHeader("Content-Language", "en"); try &#123; response.getWriter().write(error.getMessage()); &#125; catch (IOException e) &#123; LOGGER.error("Send failed response error!", e); &#125; &#125;&#125; ApplicationTx保存上下文ApplicationContext和本次请求的httprequest和httpresponse，并提供业务执行成功和失败应答逻辑。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>httpserver</tag>
        <tag>netty</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Netty实现的httpserver实现（一）]]></title>
    <url>%2F2016%2F02%2F19%2FNetty-Based-HttpServer-1%2F</url>
    <content type="text"><![CDATA[目前http协议是许多App和服务端通信的首选协议，那么对于服务端来说，一个好的httpserver一定是必不可少的了。开源的嵌入式httpServer有很多，就连JDK都自带一个轻量的httpserver，我们项目最初选择的就是JDK自带的httpserver。 从代码结构来看JDK自带的httpserver真的是非常轻量，但是好处越大却缺点也越大，随着系统复杂度的提升，这种轻量的组件越来越力不从心，对开发人员相当不友好，业务与底层耦合太强，代码复杂度越来越高的同时，性能越来越差。 最近生产环境这个server屡次出问题，已经到了没法忍受的地步，而且相对其他httpserver来说，性能并没有很高，因此改造httpserver提升日程。 接下来几篇将介绍本次项目实现的基于netty的高性能httpserver，特点如下： 基于Netty的高性能、高可靠性的特性，可以满足大多数业务场景的并发需求； 业务与底层解耦，开发人员只需关心业务细节即可； 极简的使用方式，注解式编程。 当然本人水平有限，这个组件还有很多不足之处，期待以后有机会完善。 GitHub项目地址：https://github.com/chuanqicc0430/netty-http-container]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>httpserver</tag>
        <tag>netty</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-多表查询优化]]></title>
    <url>%2F2016%2F02%2F16%2FMysql-%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[猴年开年第一篇，mark一下。 关于mysql的多表查询优化，之前一直没有注意，最近写的一个自认为还OK的sql在生产环境中出现了问题，在此记录一下。 排查机器的CPU占用100%，查看业务日志，在执行问题sql的时候抛出异常：1java.sql.SQLException: An attempt by a client to checkout a Connection has timed out. 这个库连接肯定没问题，因为别的业务也在用这个库，所以定位这条sql写的有问题。问题原因暂且放在一边，先把业务恢复了。1show processlist; 列出所有正在运行的线程信息，发现这条问题sql卡在了 Sending data 状态： 直接执行 kill 线程号，杀掉这个线程，CPU立马就降下来了。1kill 256397; 值得注意的是，Sending data 状态官方解释是:正在处理Select查询的记录，同时正在把结果发送给客户端。如果卡在这个状态这个可能有两种情况： 卡在了查询状态，也就是mysql正在收集数据； 卡在了发送数据给客户端状态，这个可能是因为查询的数据量太大，堵塞了网络IO 分析&amp;解决这个sql出现问题的原因暂时还无解，因为 explain 之后的分析结果看，这个sql还是说得过去的，测试环境跑的也没问题，但是生产环境就有问题，有空向大拿请教一下。 解决思路是使用子查询，尽可能的在子查询中缩小数据查询范围，但是优化后的sql explain之后看并没有改善太多，很奇怪： 以下是优化前和优化后的sql，请有经验的同学不吝赐教，感谢！ 12345678910111213141516171819202122232425SELECT fl.id AS `fileLogId`, fl.MD5 AS `smallPortrait`, fl.userId AS `userId`, p.id AS `portraitId`, fl.updateTime AS `updateTime`FROM `CU_Log`.`UP_FileLog` fl, `CU`.`UP_Portrait` p, `CU`.`UP_User` uWHERE fl.userId = p.userId AND fl.userId = u.userId AND u.gender = 2 AND fl.`userId` &gt; 10000000 AND fl.`userId` &lt; 80000000 AND fl.`MD5` &lt;&gt; '94F46FECE6D8611C' AND fl.fileType = 2 AND fl.actionType = 1 AND fl.MD5 = p.smallPortrait AND p.`order` = (SELECT MIN(`order`) FROM `CU`.`UP_Portrait` WHERE userId = p.userId) AND fl.`MD5` NOT IN(SELECT `md5` FROM `CU`.`CU_BlackFile`) AND fl.`id` NOT IN(SELECT `fileLogId` FROM `CustomerSystem`.`CheckAvatarLog`) AND p.id NOT IN(SELECT `portraitId` FROM `CustomerSystem`.`CheckAvatarLog`)GROUP BY p.idORDER BY `updateTime` DESCLIMIT 8; 123456789101112131415161718192021222324252627282930SELECT f.fileLogId AS `fileLogId`, f.MD5 AS `smallPortrait`, u.userId AS `userId`, f.portraitId AS `portraitId`, f.updateTime AS `updateTime`FROM (SELECT fl.`id` AS `fileLogId`, fl.`MD5`, up.id AS portraitId, fl.`updateTime`, fl.`userId` FROM `CU_Log`.`UP_FileLog` fl, `CU`.`UP_Portrait` up WHERE fl.`userId` &gt; 10000000 AND fl.`userId` &lt; 80000000 AND fl.`actionType` = 1 AND fl.`fileType` = 2 AND fl.`MD5` &lt;&gt; '94F46FECE6D8611C' AND fl.`userId` IN(SELECT u.`userId` FROM `CU`.`UP_User` u WHERE u.`userId` = fl.`userId` AND u.`gender` = 2) AND fl.`MD5` NOT IN(SELECT bf.`md5` FROM `CU`.`CU_BlackFile` bf WHERE bf.`md5` = fl.`MD5`) AND fl.userId = up.userId AND fl.MD5 = up.smallPortrait AND up.`order` = (SELECT MIN(`order`) FROM `CU`.`UP_Portrait` WHERE userId = up.userId) GROUP BY fl.`userId` HAVING `fileLogId` NOT IN(SELECT cl.`fileLogId` FROM `CustomerSystem`.`CheckAvatarLog` cl WHERE cl.`fileLogId` = `fileLogId`) ORDER BY `updateTime` DESC LIMIT 8 ) f, `CU`.`UP_User` uWHERE f.`userId` = u.`userId`]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>