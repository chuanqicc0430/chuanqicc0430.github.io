<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql总结（二）]]></title>
    <url>%2F2017%2F12%2F31%2Fmysql%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在上一篇mysql总结（一）中，提到过，Innodb索引是聚集索引，索引文件即是数据文件，每个表都有一个主键，即使用户没有显式的设置一个主键，mysql也会为这张表生成一个主键。那么，Innodb索引文件的数据结构是什么？数据查询时怎么通过索引查询的呢？ Innodb索引Innodb索引原理InnoDB使用的是聚集索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上。B+树是指多路平衡搜索树，一棵典型的B+树结构如下图关于B+树和Innodb具体怎么构建实现B+树，在这里不详细说，可参考下面两个blog，有非常详细的介绍：http://www.cnblogs.com/tgycoder/p/5077017.htmlhttp://blog.csdn.net/voidccc/article/details/40077329需要记住： B+树的非叶子节点即是索引节点，存的是顺序的主键索引区间。 所有数据都是按键值的大小顺序存放在同一层的叶子节点中，各叶子节点用指针进行连接 实际数据库B+树的高度一般在2-3，因此只需2-3次磁盘I/O就可以定位到需要的数据页，而实际情况中，B+树的非叶子节点一般直接预加载内存中，这样检索速度会更快。 主键索引查询通过主键检索数据就是一次B+树的遍历过程，时间复杂度为O(h)，h为B+树的高度。需要注意的地方是，B+树索引不能找到具体的一条记录，而是只能找到对应的数据页。把数据页从磁盘装入到内存中，再通过Page Directory（page的内部结构之一）进行二分查找，二分查找如果能找到行记录，则直接返回，如果找不到，还需要从链表中查找。 辅助索引查询辅助索引会单独构建一棵辅助索引B+树，与主键索引树不同的是，辅助索引树的叶子节点不存行的全部数据，而是只存键值和对应的主键值，因此，辅助索引树的查询需要经过两次树的检索，举例，如下图表包含三个字段，id为主键，Name为辅助索引：若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。检索如下图所示： 联合索引查询联合索引还是一个B+树，不同的是联合索引键值的数量不是1，而是大于等于2。假设两个字段a和b组成一个联合索引，如下图所示，每个节点上有两个键值，(1,1),(1,2),(2,1),(2,4),(3,1),(3,2), 数据按(a,b)顺序进行排列。因此，对于查询SELECT * FROM t WHERE a=1 AND b=2,显然可以使用(a,b)这个联合索引。对于单个a列查询SELECT * FROM t WHERE a=1也是可以使用(a,b)这个索引。但是对于b列的查询SELECT * FROM t WHERE b=2是用不到这颗B+树索引。可以看到叶节点上b的值为1、2、1、4、1、2.显然不是排序的，因此b列的查询使用不到(a,b)索引。这是一个比较重要的原则，即索引的最左前缀匹配原则，这在后面的索引使用和优化中会经常提到。 B+树索引的优势为什么不用二叉查找树比如红黑树构建索引树？为什么使用B+树而不是B树？首先，评价一个数据结构作为索引的数据结构最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的数据结构要尽量减少查找过程中磁盘I/O的存取次数。使用二叉查找树，比如红黑树构建索引树，树的高度会非常深，由于逻辑上很近的节点（父子）物理上可能很远，无法利用磁盘预读原理，会大大增加磁盘I/O次数。那么为什么不用B树？ B+树的磁盘读写代价更低B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。举个例子，假设磁盘中的一个盘块容纳16bytes，而一个关键字2bytes，一个关键字具体信息指针2bytes。一棵9阶B-tree(一个结点最多8个关键字)的内部结点需要2个盘快。而B+树内部结点只需要1个盘快(全部关键字都在叶结点的缘故？)。当需要把内部结点读入内存中的时候，B-树就比B+树多一次盘块查找时间(在磁盘中就是盘片旋转的时间)(B+树的内结点只有索引的作用，何来“把内部结点读入内存”…,对于B+树找到叶结点就可以，另外B+树可以顺序查找)。 B+树的查询效率更加稳定由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 Innodb索引使用和优化经验索引建立原则在合理的表结构设计基础上的数据查询优化，很大程度上由索引的合理使用决定，因此，索引的正确使用非常重要，索引的建立应遵循以下原则： 尽量使用主键索引，每个表都应该有一个业务无关的自增主键，在主键索引上的排序查找和范围查找的速度非常快。 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整； =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式； 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0； 索引字段应尽量小，不推荐在超大varchar或text字段上加索引; 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 索引并非是越多越好，尤其对于写操作较为频繁的业务，索引的维护成本会比较高。 为什么要尽量使用一个业务无关的自增字段作为主键？Innodb索引是聚集索引，数据记录按主键顺序存在主索引树的叶子节点，如果使用自增主键，那么每次插入新纪录，就会顺序添加到当前索引节点的后续位置，当一页写满，则开辟新的一页，每次插入不需要移动数据，减少维护索引的成本。如果使用非自增主键，插入主键的值接近随机，因此每次插入都需要移动数据，索引维护成本大，且频繁的移动可能会造成大量的磁盘碎片。 SQL优化这里的SQL优化是指对单条SQL的优化。 使用explian分析执行计划，我的习惯是，写代码的时候，对于稍微复杂的SQL一定要用explain看一下，分析索引是否用到，是否有优化空间。explian执行计划主要关注这几项： type : 查询access的方式，表的连接类型index | 索引 full | 全表扫描 ref | 参照查询，也就是等值查询 range | 范围查询 key:本次查询最终选择使用哪个索引，NULL为未使用索引 key_len:选择的索引使用的前缀长度或者整个长度 rows:查询逻辑扫描过的记录行数 extra:包含不适合在其他列中显示但十分重要的额外信息：Using index | 表示相应的select操作中使用了覆盖索引（Covering Index）【注：MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件 包含所有满足查询需要的数据的索引称为 覆盖索引】 Using where | 表示MySQL在存储引擎受到记录后进行“后过滤”（Post-filter）,如果查询未能使用索引，Using where的作用只是提醒我们MySQL将用where子句来过滤结果集 Using temporary | 表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询 Using filesort | MySQL中无法利用索引完成的排序操作称为“文件排序” inner join代left join或right join，inner join性能比较快，等值连接隐式的使用inner join，如 SELECT A.id,A.name,B.id,B.name FROM A,B WHERE A.id = B.id; 子查询的性能比join性能慢，尽量用外连接来替换子查询。 join查询应用小表驱动大表，即left join左边的表结果应尽量小，right join相反。 索引列不能参与计算，不能用于函数计算，比如from_unixtime(create_time) = ‘2017-12-31’就不能使用到索引，原因很简单，B+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该优化成create_time = unix_timestamp(‘2017-12-31’); 联合索引，只要有一列含有NULL值，这一列就不会用到索引，因此创建表时，字段不应默认为NULL。 join查询，表关联的字段应是相同数据类型，否则用不到索引。 order by的字段也应该满足最左前缀匹配原则，否则不会用到索引，例如a和b字段组成联合索引，以下order by语句可以用到索引： order by a; a = 3 order by b; order by a,b; order by a desc ,b desc; a &gt; 5 order by a; %通配符的使用，like ‘%xxx’或like ‘%xxx%’都用不到索引。 尽量使用union all或者union代替OR，尽量使用union all而不是union。 not in和&lt;&gt;都不会用到索引，not in可以用not exists代替，&lt;&gt;可以用or代替。 limit查询在数据量很大时会有性能问题，如select * from t order by id limit 100000,10;可以优化成：select * from t where id in(select id from t limit 100000,1) limit 10;或者select * from t where id between 100000 and 100010;后者性能最好。 用limit 1取得唯一行，有时要查询一张表时，如果只需要检索一行，可以使用limit 1来终止数据库引擎继续扫描整个表或者索引。 避免使用select *，会增加磁盘操作时间，增加网络延迟，浪费流量。 避免索引字段的值，因为索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。 大数量下的数据查询优化方案上一节的SQL优化针对的是具体的单条的SQL优化经验，对于大数据量下的数据查询优化，我们更应该从全局角度去思考这个问题，总结一下： 表结构的适度冗余，合理设计表，适当的反第三范式，合理冗余字段，可以极大简化数据模型。 优化SQL和索引； 加缓存，如redis或memcached； 表的垂直拆分，大系统拆成小系统，数据分离，使数据和查询分散； 水平拆分，如分库分表设计； 上面从简单到复杂，对应的实施成本也不断上升，因此，这个要跟随整个架构升级而进行。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql总结（一）]]></title>
    <url>%2F2017%2F12%2F30%2Fmysql%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[mysql是Java工程师面试时最经常被问到的技术点，因为mysql技术点太多了，很容易考察出被面试人的技术广度和深度。现总结一下mysql的基础知识点，但只是一份入门级的总结，不会太深入，期望能尽量覆盖到mysql常用知识点。另外，因为是总结，有些知识点会直接从其他地方拷贝，包括图片（图侵删）等，不喜勿喷。 本篇总结主要按照以下结构分别阐述： mysql数据引擎，重点介绍innodb数据引擎 innodb与myisam引擎的区别 innodb的逻辑存储结构 innodb 特性 innodb索引 innodb索引原理 索引的使用和优化经验。 SQL优化经验和大数据量下的数据存储优化 mysql事务和锁 mysql性能调优，主要是常用配置的优化 mysql集群和高可用 mysql主从同步原理 mysql集群搭建方案 mysql高可用方案 mysql数据引擎，innodb引擎mysql数据引擎主要有MyIsam、Innodb、Merge、Blackhole、Berkeley、CSV、Cluster/NDB等引擎。用的最多的就是MyIsam和Innodb两种引擎。 MyIsam引擎和Innodb的区别 Innodb提供了对数据库ACID事务的支持，MyIsam不支持事务； Innodb支持行级锁，MyIsam只支持表级锁； Innodb支持外键约束，MyIsam不支持； Innodb索引是聚集索引，索引文件即是数据文件，后面说到索引的时候会详细说明，MyIsam是非聚集索引，索引文件不存实际数据。 MyIsam支持全文索引，并且存储了表的行数，Innodb不支持全文索引，没有存储表的行数，因此 SELECT COUNT(*) FROM TABLE 会引起全表扫描。 Innodb的逻辑存储结构主要介绍InnoDB存储引擎表的逻辑存储以及实现。 索引组织表先看一个官方文档说明： clustered indexThe InnoDB term for a primary key index. InnoDB table storage is organized based on the values of the primary key columns,to speed up queries and sorts involving the primary key columns. For best performance, choose the primary key columns carefullybased on the most performance-critical queries. Because modifying the columns of the clustered index is an expensive operation,choose primary columns that are rarely or never updated.In the Oracle Database product, this type of table is known as an index-organized table. 翻译一下就是，Innodb数据存储是基于主键值的，通过主键可以提高查询和排序速度。因此，为了提高性能，应该谨慎的选择主键字段。修改聚集索引的字段是一个昂贵的操作，主键不应该被修改。在Oracle的数据库产品中，这种表叫做索引组织表。 按照主键的顺序存储，即索引组织表，innodb中的每个表都有一个主键，即使用户没有显式的设置一个主键，mysql也会为这张表生成一个主键，主键的生成规则： 用户显式的创建主键字段； 如果显式创建主键字段，判断表中是否有非空的唯一索引，若有，则为主键； 如果1，2都不满足，则Innodb自动生成一个6字节大小的隐式主键。 索引组织表Innodb中所有的数据都被逻辑地存放在一个空间中，称之为表空间(tablespace)。表空间又由段(segment)、区(extent)、页(page)、行（row）组成。InnoDB存储引擎的逻辑存储结构如下图表空间 Tablespace表空间是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。表空间又分为独立表空间和共享表空间。通过参数innodb_file_per_table参数来决定使用何种类型的表空间。但是需要注意的是独立表空间内只存放数据、索引和插入缓冲页，其他的数据，如回滚(undo)信息、插入缓冲索引页、系统事务信息、二次写缓冲(double write buffer)等还是放在共享表空间中。段 Segment表空间由各个段组成。常见的段有数据段、索引段、回滚段等。InnoDB存储引擎是索引组织表，因此数据及索引，索引即数据。数据段即为B+树的叶子点(leaf node segment)，索引段为B+数据的非叶子节点(non-leaf node segment)。区 Extent区是由连续页组成的空间。InnoDB存储引擎页的大小为16KB，一个区有64个连续的页组成，所以每个区的大小都是1MB。InnoDB 1.0.x版本开始引入压缩页，即每个页的大小可以在建表时通过参数key_block_size设置为2K、4K、8K，因此每个区对于页的数量就为512、256、126。InnoDB 1.2.X版本新增参数innodb_page_size将默认页的大小设置为4K、8K，但是页中的数据不是压缩，这是其中的数量同样为256、128。一句话，不论页的大小怎么变化，区的大小不变1M。但是有这样一个问题：在开启独立表空间之后，创建的表默认大小是96K，区中是64个连续的页，创建的表空间应该是1M才对呀？这是因为在每个段的开始时，先用32个页大小的碎片页(fragment page)来保存数据，在使用完这些页之后才是64个连续的页的申请。这样做是对于一些小表或者undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。页 Page页是InnoDB磁盘管理的最小单位。默认大小为16K，可以通过innodb_page_size将页的大小设置为4K、8K、16K，则所有表中页的大小都为设置值，不可以对其再次修改。除非通过mysqldump导入和导出操作来产生新的库。常见的页的类型有:数据页(B-tree Node)、undo页(unod Log Page)、系统页(System Page)、事务数据页(Transaction system Page)、插入缓冲空闲列表页(Insert Buffer Free List)、未压缩的二进制大对象页(Uncompressed BLOB Page)、压缩的二进制对象页(compressed BLOB Page)。行 RowInnoDB存储引擎是面向行的(row-oriented)，也就是说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多运行存放16K/2-200行的记录，即7992行记录。 Innodb关键特性innodb存储引擎的关键特性包括：插入缓冲，两次写，自适应哈希索引插入缓冲主键是行唯一的标识符，在应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的，因此，插入聚集索引一般是顺序的，不需要磁盘的随机读取。Innodb设计了插入缓冲，对于非聚集索引的插入或更新插入，不是每一次直接插入索引页，而是先判断插入的非聚集索引页是否在缓冲池。如果在，则直接插入；如果不在，则先放入一个插入缓冲区中，然后再以一定的频率执行插入缓冲和非聚集索引页子节点的合并操作，这时通常能将多个插入合并到一个操作中，这就大大提高了对非聚集索引执行插入和修改操作的性能。插入缓冲的两个条件：索引是辅助索引；索引不是唯一的。 两次写当数据库死机时，可能发生数据库正在写一个页面，而这个页只写来了一部分，我们称之为部分写失效。有人想如果发生写失效，可以重做日志（redo log）进行恢复。这是一个办法的但必须清楚，重做日志分析记录的是对页的物理操作，如果这个页本身已经损坏（脏页），再对其重做也没意义。当写入部分失效时，先通过页的副本来还原该页，再进行重做，这就是double write。double write由两部分组成：一部分是内存池中的double write buffer，另一部分是物理磁盘上的共享表空间中的连续的128个页，即两个区。当缓冲页的脏页刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先拷贝到内存中的double write buffer .之后通过double write buffer再分两次，每次写入1MB到共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲带来的问题。 自适应哈希引擎哈希是一种非常快的查找方法，一般情况下查找时间的复杂度为O（1），常用于连接操作，Innodb会监控对表上索引的查找，如果观察到建立哈希索引可以带来速度的提升，则自动建立哈希索引，所以称之为自适应的。自适应哈希索引通过缓冲池中的B++树构造而来，因此建立的速度会很快。而且不需要将整个表都建立哈希索引，Innodb会自动根据访问的频率和模式来为某些页建立哈希索引。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年总结]]></title>
    <url>%2F2017%2F12%2F30%2F2017%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[生活儿子的出生当是2017年的头等大事，我自己非常喜欢小孩，对于儿子的出生自然喜不自胜。儿子出生那天，我说希望儿子以后健康、独立、快乐，这也是我对儿子未来的祝福。健康要放在首位，身体好才能担得起未来你身上的责任。独立，是希望你以后要学会思考，要有自己的个性，不盲目从众，以独立之思考、决定从容应对以后的工作和生活。快乐，是对你人生的祝福，希望你能感受到这个世界的美好，有一个美好的人生，也希望你以后莫要陷入人生的陷阱，人生可以很难，也可以很简单，希望你无时无刻都快乐。 老婆生孩子糟了不少罪，很是心疼，我本不是一个浪漫的人，不会制造惊喜，日子过得波澜不惊，幸而老婆也不是很在意。新的一年，一定要多多疼爱老婆，逢年过节，一束鲜花，以表心意。 父母家人都十分健康，幸甚，又添一侄子和外甥，家族日益庞大，父母老了，还要帮忙照看孩子，也是辛苦，然总也是老来之乐。 老婆的爷爷今年去世，让我想起了我爷爷去世，爷爷去世没来的及回去见最后一面，是我心头一大憾事，世事难料，对老人需要倍加珍惜。 2018年要保持身体健康，17年阑尾炎发作以及后面的手术，糟了不少罪。跑步要坚持下去，另外需要给家人买一份合适的保险。 其他没什么值得书写，如房子至今仍未装修，买车等等，一笔带过。 工作工作上，未来虽然仍不是很通透，但今年对我来说是非常重要的一年，想明白了一些事，也到了该想清楚以后的规划的时候了，希望2018年是爆发的一年。 2017年，一整年都还是在这家创业公司，最近刚刚办理了离职，从2016年4月份加入，1年8个月的时间，不长也不短。这段时间主要做了这么几件事： 从头开始搭建服务端架构，以dubbo为基础框架，结合自研的一些组件，完成了这套服务器架构，现在看，有很多不足，但足够公司用一两年，有这么长时间，架构升级就水到渠成了。 从16年12月份到17年4月份的架构重构项目，这是我带的最大的团队和项目，包括公司产品、Android、iOS和服务器、测试团队的大部分人员，作为项目负责人，带领小伙伴完成了产品梳理、架构设计、研发一直到上线，这个项目给公司以后的发展打下了基础，可以肯定的是，至少几年内，公司业务都还是要以这个架构为基础。 17年下半年，逐步的聚焦服务端团队，进行服务端架构升级和优化，包括服务性能优化、推动服务化、自动化等。 我很感激这段经历，对我自己是一个很好的成长。16年加入的时候，服务器端只有我自己一个人，产品也从头开始梳理，一步步看着服务器端架构搭建完善起来，一步步看着产品成形上线，投入的感情岂止一点两点，然而非常可惜，到最后还是毅然离开了。 回顾这接近两年的创业经历，诸多收获，也有诸多的困惑。当产品一次次推倒重来，当老板一次又一次任性的去设计产品，当僵硬的管理体制一次次限制了开放创新，我只感到力不从心，也害怕这样的工作对我以后会产生怎样的影响，First you hate ‘em, then you get used to ‘em. Enough time passes, gets so you depend on them. That’s institutionalized. –这些墙很有趣。刚入狱的时候，你痛恨周围的高墙；慢慢地，你习惯了生活在其中；最终你会发现自己不得不依靠它而生存。这就叫体制化。《肖申克的救赎》这句台词代表了我当时离职前的心情，也是我离职的最大原因。 然而回过头来看一看，创业哪有那么容易，也许就需要这么多一次次尝试，一次次挖坑埋坑，才能争取一次成功的机会，所以要么做好接受这一切的准备，要么不要去这种创业公司。有同事说，公司正要看到希望，如果真的成功了，你会不会后悔？我想说，怎么叫后悔呢？这个公司成功了就会后悔，没成功就不会后悔么？既然做出了选择，就没有后悔这一说了，所有的事都是你这次选择需要承担的，没有后悔，没有反悔。 那这一年到底想清楚了什么？我以前说过，我的梦想是创业，这一年让我看清了，想创业，实在是还差十万八千里，最重要的是思维，其次基本功还差太多，这个基本功包括很多，技术、管理、人际等等。因此2018年，希望能尽可能的去弥补。简单来说，2018年希望做好这几件事： 技术上要不断提高，开阔技术广度； 管理上不断学习，可能会去学一下管理方面的书籍或者课程，考一个管理方面的证书； 不断认识牛人，怎么认识？一个是公司内的大神，多接触一些，另一个是要多去参加技术论坛讲座，如果自己也能上去讲一下，最好不过了。 维护好自己的技术博客，维护一个技术公众号 2018年对我自己是非常重要的一年，我自己又有诸多懒散的毛病，因此flag立下了，仍然需要下些精力去执行，否则，待明年写2018年总结时又难免一阵苦恼懊悔，非善事也。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>2017</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbox源码分析]]></title>
    <url>%2F2017%2F06%2F20%2FDubbox%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[微服务架构微服务架构相比传统的单体架构，服务之前的依赖关系更加明确，服务职责单一，服务可以自治，在良好的服务治理体系下，可以极大提高系统的容错率以及系统的弹性。 但是相对的，微服务架构由于架构复杂，也会增加很多部署和运维成本，故障排查较困难，链路调用风险增大，团队协作成本也会上升。 如果纯粹是一名技术人员，肯定首选微服务架构，但是，从架构角度考虑，架构不单单是技术的选型，技术团队的方方面面都是需要衡量的，如团队成员的技术水平，开发流程（瀑布或敏捷），项目的大小、团队成员合理的协作方式、开发效率提升等等。其实，个人认为这些才是最难得。 在项目初期，尤其是对于创业公司来说，产品开发初期侧重点势必在于产品需求的实现，但是是基础架构的搭建不是一朝一夕就能完善的，这点要做好准备，基础平台的建设开始的越早越好，当然，前提是，老板支持。 DubboxDubbox(https://github.com/dangdangdotcom/dubbox)是当当网在阿里开源的Dubbo(http://dubbo.io/)基础上扩展而来。Dubbo阿里已经不维护了，Dubbox目前当当网基本也不再维护了，但是国内的Dubbo和Dubbox的用户还是非常多的，虽然社区活跃程度较低，但是基本问题都会找到解决方案的。建议有兴趣的同学研究一下Spring Cloud，再做决定。 严格来说，Dubbo或者Dubbox不是微服务架构的全套解决方案，个人认为Dubbox只是提供了服务发现、服务治理、服务降级的RPC框架。其他的组件需要自己开发或者引入第三方开源框架，如配置管理，DB Proxy，日志以及链路调用分析，熔断机制等等。有兴趣的同学，可以看下本人开源的Linkz(https://github.com/chuanqicc0430/Linkz)，提供了几个组件，可以结合Dubbox使用。 Dubbo主要提供服务注册发现、负载均衡、服务编排、服务降级、底层通信（可选Netty或Mina）、序列化等功能，架构图如下： 接下来，我会将阅读Dubbox的源码写下来，有兴趣的同学可以一块学习。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Netty实现的httpserver实现（二）]]></title>
    <url>%2F2016%2F02%2F19%2FNetty-Based-HttpServer-2%2F</url>
    <content type="text"><![CDATA[代码结构代码结构如下图所示： 其中： app: HttpApplication是业务层的基类，继承此类以实现具体业务；HttpApplication可携带上下文ApplicationContext，ApplicationContext提供编解码方法。 core: 核心层，配置、日志、过滤器、拦截器等都在这一层实现。 appHttpApplication12345678910111213public abstract class HttpApplication&lt;C extends ApplicationContext&gt; &#123; protected HttpApplication() &#123; &#125; public abstract void load() throws Exception; public abstract void unload() throws Exception; public abstract void process(ApplicationTx&lt;C&gt; tx) throws Exception;&#125; load(): 初始化资源；unload(): 释放资源；process(ApplicationTx tx): 执行业务，tx携带用户上下文和本次请求的httprequest和httpresponse； HttpPrefix12345678910@Retention(RetentionPolicy.RUNTIME)@Target(&#123; ElementType.TYPE &#125;)public @interface HttpPrefix &#123; String path(); String protocal(); HttpMethod[] method() default HttpMethod.GET;&#125; HttpPrefix注解标注了HttpApplication的请求路径，协议和方法（Post or Get）。 ApplicationContext123456789101112131415161718192021public abstract class ApplicationContext &#123; /** * * 从数据中解码 * * @param datas * @throws IOException */ public abstract void decode(byte[] datas) throws Exception; /** * * 按需编码 * * @param demand * @return */ public abstract byte[] encode(int demands) throws IOException;&#125; 用户上下文context基类，可自定义业务需要的contenxt类型。 ApplicationTx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ApplicationTx&lt;C extends ApplicationContext&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ApplicationTx.class); private C context = null; private byte[] contextData; private HttpServletRequest request; private HttpServletResponse response; public ApplicationTx(HttpServletRequest request, HttpServletResponse response) &#123; this.request = request; this.response = response; contextData = base64decode(request.getHeader("ContextData")); &#125; public C context() &#123; return context; &#125; public void setContext(C context) &#123; this.context = context; &#125; /** * &#123;在这里补充功能说明&#125; * * @param header * @return */ private byte[] base64decode(String header) &#123; return Base64.decode(header); // 暂不用decodeFast &#125; public HttpServletRequest getRequest() &#123; return request; &#125; public HttpServletResponse getResponse() &#123; return response; &#125; /** * &#123;在这里补充功能说明&#125; * * @return */ protected byte[] extractContextData() &#123; return contextData; &#125; public void processSucceed(String responseStr,String contentType) &#123; response.setStatus(200); response.setHeader("Content-Type", contentType); response.setHeader("Content-Length", String.valueOf(responseStr.length())); response.setHeader("Content-Language", "en"); try &#123; response.getWriter().write(responseStr); &#125; catch (IOException e) &#123; LOGGER.error("Send success response error!", e); &#125; &#125; public void processFailed(CUException error) &#123; response.setStatus(error.getReturnCode()); response.setHeader("Content-Type", "text/plain"); response.setHeader("Content-Length", String.valueOf(error.getMessage().length())); response.setHeader("Content-Language", "en"); try &#123; response.getWriter().write(error.getMessage()); &#125; catch (IOException e) &#123; LOGGER.error("Send failed response error!", e); &#125; &#125;&#125; ApplicationTx保存上下文ApplicationContext和本次请求的httprequest和httpresponse，并提供业务执行成功和失败应答逻辑。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>httpserver</tag>
        <tag>netty</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Netty实现的httpserver实现（一）]]></title>
    <url>%2F2016%2F02%2F19%2FNetty-Based-HttpServer-1%2F</url>
    <content type="text"><![CDATA[目前http协议是许多App和服务端通信的首选协议，那么对于服务端来说，一个好的httpserver一定是必不可少的了。开源的嵌入式httpServer有很多，就连JDK都自带一个轻量的httpserver，我们项目最初选择的就是JDK自带的httpserver。 从代码结构来看JDK自带的httpserver真的是非常轻量，但是好处越大却缺点也越大，随着系统复杂度的提升，这种轻量的组件越来越力不从心，对开发人员相当不友好，业务与底层耦合太强，代码复杂度越来越高的同时，性能越来越差。 最近生产环境这个server屡次出问题，已经到了没法忍受的地步，而且相对其他httpserver来说，性能并没有很高，因此改造httpserver提升日程。 接下来几篇将介绍本次项目实现的基于netty的高性能httpserver，特点如下： 基于Netty的高性能、高可靠性的特性，可以满足大多数业务场景的并发需求； 业务与底层解耦，开发人员只需关心业务细节即可； 极简的使用方式，注解式编程。 当然本人水平有限，这个组件还有很多不足之处，期待以后有机会完善。 GitHub项目地址：https://github.com/chuanqicc0430/netty-http-container]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>httpserver</tag>
        <tag>netty</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-多表查询优化]]></title>
    <url>%2F2016%2F02%2F16%2FMysql-%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[猴年开年第一篇，mark一下。 关于mysql的多表查询优化，之前一直没有注意，最近写的一个自认为还OK的sql在生产环境中出现了问题，在此记录一下。 排查机器的CPU占用100%，查看业务日志，在执行问题sql的时候抛出异常：1java.sql.SQLException: An attempt by a client to checkout a Connection has timed out. 这个库连接肯定没问题，因为别的业务也在用这个库，所以定位这条sql写的有问题。问题原因暂且放在一边，先把业务恢复了。1show processlist; 列出所有正在运行的线程信息，发现这条问题sql卡在了 Sending data 状态： 直接执行 kill 线程号，杀掉这个线程，CPU立马就降下来了。1kill 256397; 值得注意的是，Sending data 状态官方解释是:正在处理Select查询的记录，同时正在把结果发送给客户端。如果卡在这个状态这个可能有两种情况： 卡在了查询状态，也就是mysql正在收集数据； 卡在了发送数据给客户端状态，这个可能是因为查询的数据量太大，堵塞了网络IO 分析&amp;解决这个sql出现问题的原因暂时还无解，因为 explain 之后的分析结果看，这个sql还是说得过去的，测试环境跑的也没问题，但是生产环境就有问题，有空向大拿请教一下。 解决思路是使用子查询，尽可能的在子查询中缩小数据查询范围，但是优化后的sql explain之后看并没有改善太多，很奇怪： 以下是优化前和优化后的sql，请有经验的同学不吝赐教，感谢！ 12345678910111213141516171819202122232425SELECT fl.id AS `fileLogId`, fl.MD5 AS `smallPortrait`, fl.userId AS `userId`, p.id AS `portraitId`, fl.updateTime AS `updateTime`FROM `CU_Log`.`UP_FileLog` fl, `CU`.`UP_Portrait` p, `CU`.`UP_User` uWHERE fl.userId = p.userId AND fl.userId = u.userId AND u.gender = 2 AND fl.`userId` &gt; 10000000 AND fl.`userId` &lt; 80000000 AND fl.`MD5` &lt;&gt; '94F46FECE6D8611C' AND fl.fileType = 2 AND fl.actionType = 1 AND fl.MD5 = p.smallPortrait AND p.`order` = (SELECT MIN(`order`) FROM `CU`.`UP_Portrait` WHERE userId = p.userId) AND fl.`MD5` NOT IN(SELECT `md5` FROM `CU`.`CU_BlackFile`) AND fl.`id` NOT IN(SELECT `fileLogId` FROM `CustomerSystem`.`CheckAvatarLog`) AND p.id NOT IN(SELECT `portraitId` FROM `CustomerSystem`.`CheckAvatarLog`)GROUP BY p.idORDER BY `updateTime` DESCLIMIT 8; 123456789101112131415161718192021222324252627282930SELECT f.fileLogId AS `fileLogId`, f.MD5 AS `smallPortrait`, u.userId AS `userId`, f.portraitId AS `portraitId`, f.updateTime AS `updateTime`FROM (SELECT fl.`id` AS `fileLogId`, fl.`MD5`, up.id AS portraitId, fl.`updateTime`, fl.`userId` FROM `CU_Log`.`UP_FileLog` fl, `CU`.`UP_Portrait` up WHERE fl.`userId` &gt; 10000000 AND fl.`userId` &lt; 80000000 AND fl.`actionType` = 1 AND fl.`fileType` = 2 AND fl.`MD5` &lt;&gt; '94F46FECE6D8611C' AND fl.`userId` IN(SELECT u.`userId` FROM `CU`.`UP_User` u WHERE u.`userId` = fl.`userId` AND u.`gender` = 2) AND fl.`MD5` NOT IN(SELECT bf.`md5` FROM `CU`.`CU_BlackFile` bf WHERE bf.`md5` = fl.`MD5`) AND fl.userId = up.userId AND fl.MD5 = up.smallPortrait AND up.`order` = (SELECT MIN(`order`) FROM `CU`.`UP_Portrait` WHERE userId = up.userId) GROUP BY fl.`userId` HAVING `fileLogId` NOT IN(SELECT cl.`fileLogId` FROM `CustomerSystem`.`CheckAvatarLog` cl WHERE cl.`fileLogId` = `fileLogId`) ORDER BY `updateTime` DESC LIMIT 8 ) f, `CU`.`UP_User` uWHERE f.`userId` = u.`userId`]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>